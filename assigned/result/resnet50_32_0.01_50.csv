Epoch,TrainingLoss,LearningRate,TrainingAccuracy
1,4.6548,0.01,0.04408
2,4.32134,0.02,0.05572
3,4.02172,0.02,0.07666
4,3.86853,0.02,0.09938
5,3.61503,0.02,0.13856
6,3.46705,0.02,0.16772
7,3.35899,0.02,0.18414
8,3.27453,0.02,0.20034
9,3.19691,0.02,0.21258
10,3.0934,0.02,0.23418
11,3.08493,0.02,0.23556
12,3.00033,0.02,0.25106
13,2.89473,0.02,0.26876
14,2.81142,0.02,0.28712
15,2.76958,0.02,0.29604
16,2.70286,0.02,0.30606
17,2.66677,0.02,0.32016
18,2.6312,0.02,0.32432
19,2.59352,0.02,0.33234
20,2.57079,0.02,0.33622
21,2.52887,0.02,0.34594
22,2.50417,0.02,0.35
23,2.48125,0.02,0.3582
24,2.4502,0.02,0.36056
25,2.43596,0.02,0.3662
26,2.41309,0.02,0.3706
27,2.38666,0.02,0.3755
28,2.35707,0.02,0.38054
29,2.33107,0.02,0.38838
30,2.31309,0.02,0.38684
31,2.29614,0.02,0.39466
32,2.2684,0.02,0.40084
33,2.25474,0.02,0.40028
34,2.24779,0.02,0.40586
35,2.23092,0.02,0.40608
36,2.20838,0.02,0.41144
37,2.20029,0.02,0.41324
38,2.18234,0.02,0.41876
39,2.17382,0.02,0.41966
40,2.15438,0.02,0.42496
41,2.15089,0.02,0.42508
42,2.13492,0.02,0.42848
43,2.13398,0.02,0.4294
44,2.12009,0.02,0.43472
45,2.11384,0.02,0.434
46,2.10575,0.02,0.43604
47,2.1026,0.02,0.43598
48,2.08748,0.02,0.43964
49,2.08572,0.02,0.43886
50,2.0805,0.02,0.43902
